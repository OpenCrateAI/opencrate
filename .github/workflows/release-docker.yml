name: Release Docker

on:
  push:
    tags:
      - "v*.*.*"
      - "v*.*.*-rc.*"
  schedule:
    - cron: "0 3 * * 0" # Weekly on Sunday at 03:00
  workflow_dispatch:
    inputs:
      REBUILD_BASE:
        description: "Force a pull of new base layers and refresh the cache?"
        required: true
        type: boolean
        default: false

# 1. Concurrency: Cancel in-progress runs for the same PR
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: false # Never cancel release builds

# 2. Permissions: Least privilege (Read-only by default)
permissions:
  contents: read

jobs:
  static-checks:
    name: Static Checks
    runs-on: ubuntu-latest
    timeout-minutes: 5
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: "3.10"

      - name: Install Development Packages
        run: |
          python3.10 -m pip install --upgrade pip --root-user-action=ignore
          python3.10 -m pip install types-docker ".[ci]" --root-user-action=ignore --extra-index-url https://download.pytorch.org/whl/cpu

      - name: Running tests
        run: make test

  generate-dockerfiles:
    name: Generate Dockerfiles & Matrix
    runs-on: ubuntu-latest
    timeout-minutes: 2
    outputs:
      version: ${{ steps.get_version.outputs.VERSION }}
      rebuild_flag: ${{ github.event_name == 'schedule' || github.event.inputs.REBUILD_BASE }}
      # Output the python versions as a JSON array for the matrix
      python_versions_json: ${{ steps.set_matrix.outputs.PYTHON_VERSIONS_JSON }}
      is_prerelease: ${{ contains(github.ref, '-rc.') }}
    steps:
      - uses: actions/checkout@v4

      - name: Get the version from VERSION file
        id: get_version
        run: echo "VERSION=$(cat VERSION | tr -d '\n')" >> $GITHUB_OUTPUT

      - uses: actions/setup-python@v5
        with:
          python-version: "3.10"

      - name: Install Python dependencies
        run: pip install rich loguru

      # Read the PYTHON_VERSIONS file and convert to JSON array
      - name: Set Python Matrix
        id: set_matrix
        run: |
          ALL_VERSIONS=$(python3 -c 'import json; print(json.dumps([line.strip() for line in open("PYTHON_VERSIONS") if line.strip()]))')
          echo "Detected Main/Schedule: Using ALL Versions."
          echo "PYTHON_VERSIONS_JSON=$ALL_VERSIONS" >> $GITHUB_OUTPUT

      - name: Generate Dockerfiles
        run: make docker-generate

      - name: Upload Dockerfiles
        uses: actions/upload-artifact@v4
        with:
          name: generated-dockerfiles
          path: ./docker/dockerfiles

  build-and-test-images:
    name: Build & Test ${{ matrix.runtime }}-py${{ matrix.python_version }}
    runs-on: ubuntu-latest
    needs: [static-checks, generate-dockerfiles]
    timeout-minutes: 10
    strategy:
      fail-fast: false
      matrix:
        runtime: [cpu, cuda]
        # Use the JSON array generated in the previous job
        python_version: ${{ fromJson(needs.generate-dockerfiles.outputs.python_versions_json) }}

    steps:
      # Fetch depth 2 is required for git diff HEAD~1 HEAD to work
      - uses: actions/checkout@v4
        with:
          fetch-depth: 2

      - name: Download Dockerfiles artifact
        uses: actions/download-artifact@v4
        with:
          name: generated-dockerfiles
          path: ./docker/dockerfiles

      - uses: docker/setup-buildx-action@v3

      - name: Login to Docker Hub
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKERHUB_USERNAME }}
          password: ${{ secrets.DOCKERHUB_TOKEN }}

      # Determine build strategy based on event type and dependency changes
      - name: Determine Build Strategy
        id: check_changes
        run: |
          EVENT_NAME="${{ github.event_name }}"
          REBUILD_FLAG="${{ needs.generate-dockerfiles.outputs.rebuild_flag }}"

          CHANGED=$(make ci-check-dependency-changes)

          # Fresh build (--pull --no-cache) if REBUILD_FLAG=true OR dependencies changed
          if [ "$REBUILD_FLAG" = "true" ]; then
            echo "REBUILD_FLAG=true" >> $GITHUB_OUTPUT
            echo "CACHE_UPDATE=true" >> $GITHUB_OUTPUT
            echo -e "\033[1;38;5;214mBuild Strategy: Fresh build (--pull --no-cache) + update remote cache (REBUILD_FLAG=true)\033[0m"
          elif [ "$CHANGED" = "true" ]; then
            echo "REBUILD_FLAG=true" >> $GITHUB_OUTPUT
            echo "CACHE_UPDATE=true" >> $GITHUB_OUTPUT
            echo -e "\033[1;38;5;214mBuild Strategy: Fresh build (--pull --no-cache) + update remote cache (Dependencies changed)\033[0m"
          else
            echo "REBUILD_FLAG=false" >> $GITHUB_OUTPUT
            echo "CACHE_UPDATE=false" >> $GITHUB_OUTPUT
            echo -e "\033[1;38;5;214mBuild Strategy: Using remote cache (read-only)\033[0m"
          fi

      - name: Build Image
        run: |
          make ci-build MODE=test \
            RUNTIME=${{ matrix.runtime }} \
            PYTHON_VERSION=${{ matrix.python_version }} \
            VERSION=${{ needs.generate-dockerfiles.outputs.version }} \
            REBUILD_FLAG=${{ steps.check_changes.outputs.REBUILD_FLAG }} \
            CACHE_UPDATE=${{ steps.check_changes.outputs.CACHE_UPDATE }}

      - name: Test Image
        run: |
          make docker-test \
            DEPS=ci \
            RUNTIME=${{ matrix.runtime }} \
            PYTHON_VERSION=${{ matrix.python_version }} \
            VERSION=${{ needs.generate-dockerfiles.outputs.version }}

      - name: Upload Test Logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-logs-${{ matrix.runtime }}-py${{ matrix.python_version }}
          path: ./tests/logs

      - name: Export Image Digest
        run: |
          FULL_IMAGE="braindotai/opencrate-${{ matrix.runtime }}-py${{ matrix.python_version }}:${{ needs.generate-dockerfiles.outputs.version }}"
          DIGEST=$(docker inspect --format='{{.RootFS.Layers}}' $FULL_IMAGE | sha256sum | cut -d' ' -f1)
          echo "Computed Digest: $DIGEST"
          echo "$DIGEST" > digest-${{ matrix.runtime }}-py${{ matrix.python_version }}.txt

      - name: Upload Image Digest Artifact
        uses: actions/upload-artifact@v4
        with:
          name: digest-${{ matrix.runtime }}-py${{ matrix.python_version }}
          path: digest-${{ matrix.runtime }}-py${{ matrix.python_version }}.txt

  build-and-push-images:
    name: Push ${{ matrix.runtime }}-py${{ matrix.python_version }}
    runs-on: ubuntu-latest
    needs: [generate-dockerfiles, build-and-test-images]
    strategy:
      fail-fast: false
      matrix:
        runtime: [cpu, cuda]
        python_version: ${{ fromJson(needs.generate-dockerfiles.outputs.python_versions_json) }}
    steps:
      - uses: actions/checkout@v4

      - name: Download Dockerfiles artifact
        uses: actions/download-artifact@v4
        with:
          name: generated-dockerfiles
          path: ./docker/dockerfiles

      - name: Download Image Digest
        uses: actions/download-artifact@v4
        with:
          name: digest-${{ matrix.runtime }}-py${{ matrix.python_version }}
          path: .

      - uses: docker/setup-qemu-action@v3
      - uses: docker/setup-buildx-action@v3

      - name: Login to Docker Hub
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKERHUB_USERNAME }}
          password: ${{ secrets.DOCKERHUB_TOKEN }}

      - name: Build and Load for Digest Check
        # Adding REBUILD_FLAG=false and CACHE_UPDATE=false explicitly ensures the push job only reads from remote cache
        run: |
          make ci-build MODE=test \
            RUNTIME=${{ matrix.runtime }} \
            PYTHON_VERSION=${{ matrix.python_version }} \
            VERSION=${{ needs.generate-dockerfiles.outputs.version }} \
            REBUILD_FLAG=false \
            CACHE_UPDATE=false

      - name: Verify Integrity
        run: |
          # 1. Read Expected Digest from Test Job
          EXPECTED=$(cat digest-${{ matrix.runtime }}-py${{ matrix.python_version }}.txt)

          # 2. Get Actual Digest from the image we just loaded
          FULL_IMAGE="braindotai/opencrate-${{ matrix.runtime }}-py${{ matrix.python_version }}:${{ needs.generate-dockerfiles.outputs.version }}"
          ACTUAL=$(docker inspect --format='{{.RootFS.Layers}}' $FULL_IMAGE | sha256sum | cut -d' ' -f1)

          echo "Expected Digest: $EXPECTED"
          echo "Actual Digest:   $ACTUAL"

          # 3. Compare and Fail if Mismatch
          if [ "$EXPECTED" != "$ACTUAL" ]; then
            echo -e "\033[1;31m✗ Integrity check failed, aborting push to protect registry. ✗\033[0m"
            echo -e "\033[1;31m! Try rerunning build-and-test-images !\033[0m"
            exit 1
          fi
          echo -e "\033[1;32m✓ Integrity verified, proceeding to push to registry. ✓\033[0m"

      # Push job ALWAYS uses cache from test job - ensuring we push exactly what we tested
      # Adding REBUILD_FLAG=false and CACHE_UPDATE=false explicitly ensures the push job only reads from remote cache
      - name: Build and Push Image
        run: |
          make ci-build MODE=push \
            RUNTIME=${{ matrix.runtime }} \
            PYTHON_VERSION=${{ matrix.python_version }} \
            VERSION=${{ needs.generate-dockerfiles.outputs.version }} \
            REBUILD_FLAG=false \
            CACHE_UPDATE=false

  release-latest:
    name: Tag "latest"
    runs-on: ubuntu-latest
    needs: [generate-dockerfiles, build-and-push-images]
    if: success() && github.event_name == 'push' && github.ref_type == 'tag' && needs.generate-dockerfiles.outputs.is_prerelease == 'false'
    steps:
      - name: Login to Docker Hub
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKERHUB_USERNAME }}
          password: ${{ secrets.DOCKERHUB_TOKEN }}

      # We don't need to checkout code here necessarily, but if the Makefile needs it:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Tag and Push "latest" tag
        run: make ci-release VERSION=${{ needs.generate-dockerfiles.outputs.version }}
